{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to treat this as a classification problem by creating a new binary\n",
    "variable affair (did the woman have at least one affair?) and trying to\n",
    "predict the classification for each woman.\n",
    "\n",
    "#### Dataset\n",
    "The dataset I chose is the affairs dataset that comes with Statsmodels. It\n",
    "was derived from a survey of women in 1974 by Redbook magazine, in\n",
    "which married women were asked about their participation in extramarital\n",
    "affairs. More information about the study is available in a 1978 paper from\n",
    "the Journal of Political Economy.\n",
    "\n",
    "#### Description of Variables\n",
    "The dataset contains 6366 observations of 9 variables: \n",
    "\n",
    "rate_marriage: woman's rating of her marriage (1 = very poor, 5 =very good)\n",
    "\n",
    "age: woman's age\n",
    "\n",
    "yrs_married: number of years married\n",
    "\n",
    "children: number of children\n",
    "\n",
    "religious: woman's rating of how religious she is (1 = not religious, 4 =\n",
    "strongly religious)\n",
    "\n",
    "educ: level of education (9 = grade school, 12 = high school, 14 =\n",
    "some college, 16 = college graduate, 17 = some graduate school, 20\n",
    "= advanced degree)\n",
    "\n",
    "occupation: woman's occupation (1 = student, 2 = farming/semiskilled/unskilled, 3 = \"white collar\", 4 =\n",
    "teacher/nurse/writer/technician/skilled, 5 = managerial/business, 6 =\n",
    "professional with advanced degree)\n",
    "\n",
    "occupation_husb: husband's occupation (same coding as above)\n",
    "\n",
    "affairs: time spent in extra-marital affairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from patsy import dmatrices\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.model_selection  import train_test_split \n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection  import cross_val_score \n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, roc_auc_score\n",
    "%matplotlib inline\n",
    "dta = sm.datasets.fair.load_pandas().data\n",
    "\n",
    "#add \"affair\" column: 1 represents having affairs, 0 represents not \n",
    "dta['affair'] = (dta.affairs > 0).astype(int)\n",
    "y, X = dmatrices('affair ~ rate_marriage + age + yrs_married + children + religious + educ + C(occupation) + C(occupation_husb)', dta, return_type=\"dataframe\") \n",
    "X = X.rename(columns =\n",
    "{'C(occupation)[T.2.0]':'occ_2',\n",
    "'C(occupation)[T.3.0]':'occ_3',\n",
    "'C(occupation)[T.4.0]':'occ_4',\n",
    "'C(occupation)[T.5.0]':'occ_5',\n",
    "'C(occupation)[T.6.0]':'occ_6',\n",
    "'C(occupation_husb)[T.2.0]':'occ_husb_2',\n",
    "'C(occupation_husb)[T.3.0]':'occ_husb_3',\n",
    "'C(occupation_husb)[T.4.0]':'occ_husb_4',\n",
    "'C(occupation_husb)[T.5.0]':'occ_husb_5',\n",
    "'C(occupation_husb)[T.6.0]':'occ_husb_6'})\n",
    "y = np.ravel(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=0 )\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "classi = model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7241921005385996"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classi.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypredict = classi.predict(x_test)\n",
    "ypredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7308900523560209"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test,ypredict)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7243234303881204"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(LogisticRegression(max_iter=1000), X, y, scoring='accuracy', cv=10)\n",
    "scores\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1168,  135],\n",
       "       [ 379,  228]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrx = confusion_matrix(y_test,ypredict)\n",
    "conf_matrx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positive = conf_matrx[0][0]\n",
    "false_positive = conf_matrx[0][1]\n",
    "false_negative = conf_matrx[1][0]\n",
    "true_negative = conf_matrx[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7308900523560209"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy\n",
    "\n",
    "accuracy = (true_positive + true_negative) / (true_positive+true_negative+false_negative+false_positive)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7550096961861668"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall\n",
    "\n",
    "recall = true_positive/(true_positive+false_negative)\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.896392939370683"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Precisio\n",
    "\n",
    "precision = true_positive/(true_positive+false_positive)\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8196491228070175"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#F1 score\n",
    "\n",
    "F1 =  2*(recall * precision) / (recall + precision)\n",
    "F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.77446853, 0.22553147]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample = np.array([1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 3, 25, 3, 1, 4, 16]).reshape(1, -1)\n",
    "model.predict_proba(test_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "23% probability of affair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
